{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This script uses OpenCV's haarcascade (face and eye cascade) to detect face\n",
    "and eyes in a video feed which can be inputted through a webcam.'''\n",
    "\n",
    "#Import necessary libraries\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "#Load face cascade and hair cascade from haarcascades folder\n",
    "face_cascade = cv.CascadeClassifier(\"haarcascades/haarcascade_frontalface_default.xml\")\n",
    "eye_cascade = cv.CascadeClassifier(\"haarcascades/haarcascade_eye.xml\")\n",
    "\n",
    "#Capture video from webcam\n",
    "video_capture = cv.VideoCapture(0)\n",
    "\n",
    "#Read all frames from webcam\n",
    "while True:\n",
    "    ret, frame = video_capture.read()\n",
    "    frame = cv.flip(frame,1) #Flip so that video feed is not flipped, and appears mirror like.\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "\n",
    "    cv.imshow('Video', frame)\n",
    "\n",
    "    if(cv.waitKey(1) & 0xFF == ord('q')):\n",
    "        break\n",
    "\n",
    "#Finally when video capture is over, release the video capture and destroyAllWindows\n",
    "video_capture.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-cf0feb9d78df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[0mtracker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFollow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m \u001b[0mtracker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalibrate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    279\u001b[0m \u001b[0mtracker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_thread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[0mtracker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-cf0feb9d78df>\u001b[0m in \u001b[0;36mcalibrate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# Deep copy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[1;31m# Size of frame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "from threading import Thread\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "class Follow():\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        # Capture the webcam\n",
    "        self.camera = cv2.VideoCapture(-1)\n",
    "        self.camera.set(3,1920)\n",
    "        self.camera.set(4,1080)\n",
    "\n",
    "        # Ball (BGR)\n",
    "        self.bl = [40, 60, 130]\n",
    "        self.bu = [55, 255, 255]\n",
    "\n",
    "        # Points for our tracker\n",
    "        self.bpts = deque()\n",
    "\n",
    "        # Line trail\n",
    "        self.line = (0, 89, 217)\n",
    "\n",
    "        # Min/max radius\n",
    "        self.min_radius = 10\n",
    "        self.max_radius = 100\n",
    "\n",
    "        # Line thickness\n",
    "        self.buff = 10\n",
    "\n",
    "        # Pause drawing\n",
    "        self.pause = 0\n",
    "\n",
    "        # Size of roi square\n",
    "        self.roi_size = 10\n",
    "\n",
    "        # List of colors\n",
    "        self.colors = {\n",
    "            114: (0, 0, 255),     # red\n",
    "            98: (255, 0, 0),      # blue\n",
    "            103: (85, 255, 127),  # green\n",
    "            121: (0, 255, 255),   # yellow\n",
    "            111: (0, 89, 217),    # orange\n",
    "            107: (0, 0, 0),       # black\n",
    "            119: (255, 255, 255)  # white\n",
    "        }\n",
    "\n",
    "        # Morphology Kernel\n",
    "        self.kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))\n",
    "\n",
    "\n",
    "\n",
    "    def calibrate(self):\n",
    "\n",
    "        # Roi size\n",
    "        r = self.roi_size\n",
    "\n",
    "        # Calibration count\n",
    "        i = 0\n",
    "\n",
    "        while not self.pause:\n",
    "\n",
    "            # Grab the current web frame\n",
    "            frame = self.camera.read()[1]\n",
    "\n",
    "            # Deep copy\n",
    "            img = frame.copy()\n",
    "\n",
    "            # Size of frame\n",
    "            y, x, _ = np.shape(img)\n",
    "\n",
    "            # Image locations\n",
    "            if i == 0:\n",
    "                xx, yy = int(x - x/10), int(y/8)                    # Upper Left\n",
    "            elif i == 1:\n",
    "                xx, yy = int(x - x/10), int(y - y/2)                # Center Left\n",
    "            elif i == 2:\n",
    "                xx, yy = int(x - x/10), int(y - y/8)                # Lower Left\n",
    "            elif i == 3:\n",
    "                xx, yy = int(x - x/2), int(y/8)                     # Upper Center\n",
    "            elif i == 4:\n",
    "                xx, yy = int(x - x/2), int(y - y/2)                 # Center Center\n",
    "            elif i == 5:\n",
    "                xx, yy = int(x - x/2), int(y - y/8)                 # Lower Center\n",
    "            elif i == 6:\n",
    "                xx, yy = int(x/10), int(y/8)                        # Upper Right\n",
    "            elif i == 7:\n",
    "                xx, yy = int(x/10), int(y - y/2)                    # Center Right\n",
    "            elif i == 8:\n",
    "                xx, yy = int(x/10), int(y - y/8)                    # Lower Right\n",
    "\n",
    "            # Draw square\n",
    "            cv2.rectangle(img, (xx-r, yy-r), (xx+r, yy+r), (0, 0, 255), 2)\n",
    "\n",
    "            # Flip frame to help with movement\n",
    "            img = cv2.flip(img, 1)\n",
    "\n",
    "            # Show the frame\n",
    "            cv2.imshow('Frame', img)\n",
    "\n",
    "            # exit on escape\n",
    "            k = cv2.waitKey(5) & 0xFF\n",
    "\n",
    "            if k == 27:\n",
    "                self.halt = 1\n",
    "                break\n",
    "\n",
    "            # Capture color on c\n",
    "            if k == 99:\n",
    "                roi = frame[yy-r:yy+r,xx-r:xx+r]\n",
    "\n",
    "                # Append the hsv data for statistics\n",
    "                if 'hsv' in locals():\n",
    "                    np.append(hsv, cv2.cvtColor(roi, cv2.COLOR_BGR2HSV))\n",
    "                else:\n",
    "                    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "                i += 1\n",
    "\n",
    "                if i == 9:\n",
    "                    break\n",
    "\n",
    "        image_mean = np.ceil(hsv.mean(axis=(0,1)))\n",
    "        image_std = np.ceil(hsv.std(axis=(0,1)))\n",
    "\n",
    "        self.bl = image_mean - image_std * 2\n",
    "        self.bu = image_mean + image_std * 2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def filter_objects(self, cnts):\n",
    "\n",
    "        c = max(cnts, key=cv2.contourArea)\n",
    "\n",
    "        ((x, y), radius) = cv2.minEnclosingCircle(c)\n",
    "\n",
    "        if radius > self.min_radius and radius < self.max_radius:\n",
    "\n",
    "            M = cv2.moments(c)\n",
    "\n",
    "            center = (int(M[\"m10\"] / M[\"m00\"]), int(M[\"m01\"] / M[\"m00\"]))\n",
    "\n",
    "            return ((int(x), int(y)), int(radius), center)\n",
    "\n",
    "        return ((0, 0), 0, None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def track(self, hsv):\n",
    "\n",
    "        # Construct a mask\n",
    "        mask = cv2.inRange(hsv, self.bl, self.bu)\n",
    "        mask = cv2.erode(mask, self.kernel, iterations=1)\n",
    "        mask = cv2.dilate(mask, self.kernel, iterations=1)\n",
    "\n",
    "        # Short code for frame\n",
    "        frame = self.frame\n",
    "\n",
    "        # Find contours in the mask and initialize the current (x,y) center of ball\n",
    "        cnts = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
    "\n",
    "        # Continue only if at least one contour was found\n",
    "        if len(cnts) > 0 and not self.pause:\n",
    "\n",
    "            ((x, y), radius, center) = self.filter_objects(cnts)\n",
    "\n",
    "            # Update the points deque\n",
    "            if center is not None:\n",
    "                self.bpts.append([center, self.line, self.buff])\n",
    "\n",
    "        for p in self.bpts:\n",
    "            cv2.circle(frame, p[0], p[2], p[1], -1)\n",
    "\n",
    "        # First flip image... Don't want to have to write backwards ;-)\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        return frame\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Use a thread for speed\n",
    "    def start_thread(self):\n",
    "\n",
    "        # Stop flag\n",
    "        self.halt = 0\n",
    "\n",
    "        # Initialize thread\n",
    "        self.t = Thread(target=self.update)\n",
    "\n",
    "        # Make daemon (dies automatically)\n",
    "        self.t.daemon = True\n",
    "\n",
    "        # Start the thread\n",
    "        self.t.start()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Thread worker function\n",
    "    def update(self):\n",
    "\n",
    "        while not self.halt:\n",
    "\n",
    "            # Grab the current web frame\n",
    "            self.frame = self.camera.read()[1]\n",
    "\n",
    "        # Release the Camera\n",
    "        self.camera.release()\n",
    "\n",
    "        # Destroy all windows\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def capture(self):\n",
    "\n",
    "        # Wait a moment until we have a frame instance\n",
    "        cv2.waitKey(500) & 0xFF\n",
    "\n",
    "        # Loop untill we stop\n",
    "        while not self.halt:\n",
    "\n",
    "            # Convert to HSV colorspace\n",
    "            hsv = cv2.cvtColor(self.frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "            # Look for balls\n",
    "            frame = self.track(hsv)\n",
    "\n",
    "            # show the frame to our screen\n",
    "            cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "            # exit on escape\n",
    "            k = cv2.waitKey(5) & 0xFF\n",
    "\n",
    "            if k == 27:\n",
    "                self.halt = 1\n",
    "                break\n",
    "\n",
    "            # Pause (p)\n",
    "            elif k == 112:\n",
    "                if self.pause:\n",
    "                    self.pause = 0\n",
    "                else:\n",
    "                    self.pause = 1\n",
    "\n",
    "            # Clear the screen ( c )\n",
    "            elif k == 99:\n",
    "                self.bpts = deque()\n",
    "\n",
    "            # Colors\n",
    "            elif k in self.colors:\n",
    "                self.line = self.colors[k]\n",
    "\n",
    "            # Draw small ( s )\n",
    "            elif k == 115:\n",
    "                self.buff = 5\n",
    "\n",
    "            # Draw medium ( m )\n",
    "            elif k == 109:\n",
    "                self.buff = 10\n",
    "\n",
    "            # Draw large ( l )\n",
    "            elif k == 108:\n",
    "                self.buff = 15\n",
    "\n",
    "\n",
    "tracker = Follow()\n",
    "tracker.calibrate();\n",
    "tracker.start_thread()\n",
    "tracker.capture()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-5-a7da40e36f9a>, line 49)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-a7da40e36f9a>\"\u001b[1;36m, line \u001b[1;32m49\u001b[0m\n\u001b[1;33m    © 2021 GitHub, Inc.\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "# Read the image file\n",
    "image = cv2.imread('car0.JPG')\n",
    "# Convert to Grayscale Image\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#Canny Edge Detection\n",
    "canny_edge = cv2.Canny(gray_image, 170, 200)\n",
    "\n",
    "# Find contours based on Edges\n",
    "contours, new  = cv2.findContours(canny_edge.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contours=sorted(contours, key = cv2.contourArea, reverse = True)[:30]\n",
    "\n",
    "# Initialize license Plate contour and x,y coordinates\n",
    "contour_with_license_plate = None\n",
    "license_plate = None\n",
    "x = None\n",
    "y = None\n",
    "w = None\n",
    "h = None\n",
    "\n",
    "# Find the contour with 4 potential corners and creat ROI around it\n",
    "for contour in contours:\n",
    "        # Find Perimeter of contour and it should be a closed contour\n",
    "        perimeter = cv2.arcLength(contour, True)\n",
    "        approx = cv2.approxPolyDP(contour, 0.01 * perimeter, True)\n",
    "        if len(approx) == 4: #see whether it is a Rect\n",
    "            contour_with_license_plate = approx\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            license_plate = gray_image[y:y + h, x:x + w]\n",
    "            break\n",
    "\n",
    "# Removing Noise from the detected image, before sending to Tesseract\n",
    "license_plate = cv2.bilateralFilter(license_plate, 11, 17, 17)\n",
    "(thresh, license_plate) = cv2.threshold(license_plate, 150, 180, cv2.THRESH_BINARY)\n",
    "\n",
    "#Text Recognition\n",
    "text = pytesseract.image_to_string(license_plate)\n",
    "#Draw License Plate and write the Text\n",
    "image = cv2.rectangle(image, (x,y), (x+w,y+h), (0,0,255), 3) \n",
    "image = cv2.putText(image, text, (x-100,y-50), cv2.FONT_HERSHEY_SIMPLEX, 3, (0,255,0), 6, cv2.LINE_AA)\n",
    "\n",
    "print(\"License Plate :\", text)\n",
    "\n",
    "cv2.imshow(\"License Plate Detection\",image)\n",
    "cv2.waitKey(0)\n",
    "© 2021 GitHub, Inc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-6-a7da40e36f9a>, line 49)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-6-a7da40e36f9a>\"\u001b[1;36m, line \u001b[1;32m49\u001b[0m\n\u001b[1;33m    © 2021 GitHub, Inc.\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "# Read the image file\n",
    "image = cv2.imread('car0.JPG')\n",
    "# Convert to Grayscale Image\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#Canny Edge Detection\n",
    "canny_edge = cv2.Canny(gray_image, 170, 200)\n",
    "\n",
    "# Find contours based on Edges\n",
    "contours, new  = cv2.findContours(canny_edge.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contours=sorted(contours, key = cv2.contourArea, reverse = True)[:30]\n",
    "\n",
    "# Initialize license Plate contour and x,y coordinates\n",
    "contour_with_license_plate = None\n",
    "license_plate = None\n",
    "x = None\n",
    "y = None\n",
    "w = None\n",
    "h = None\n",
    "\n",
    "# Find the contour with 4 potential corners and creat ROI around it\n",
    "for contour in contours:\n",
    "        # Find Perimeter of contour and it should be a closed contour\n",
    "        perimeter = cv2.arcLength(contour, True)\n",
    "        approx = cv2.approxPolyDP(contour, 0.01 * perimeter, True)\n",
    "        if len(approx) == 4: #see whether it is a Rect\n",
    "            contour_with_license_plate = approx\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            license_plate = gray_image[y:y + h, x:x + w]\n",
    "            break\n",
    "\n",
    "# Removing Noise from the detected image, before sending to Tesseract\n",
    "license_plate = cv2.bilateralFilter(license_plate, 11, 17, 17)\n",
    "(thresh, license_plate) = cv2.threshold(license_plate, 150, 180, cv2.THRESH_BINARY)\n",
    "\n",
    "#Text Recognition\n",
    "text = pytesseract.image_to_string(license_plate)\n",
    "#Draw License Plate and write the Text\n",
    "image = cv2.rectangle(image, (x,y), (x+w,y+h), (0,0,255), 3) \n",
    "image = cv2.putText(image, text, (x-100,y-50), cv2.FONT_HERSHEY_SIMPLEX, 3, (0,255,0), 6, cv2.LINE_AA)\n",
    "\n",
    "print(\"License Plate :\", text)\n",
    "\n",
    "cv2.imshow(\"License Plate Detection\",image)\n",
    "cv2.waitKey(0)\n",
    "© 2021 GitHub, Inc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
